{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_graph_modelling_language_using_select_speaker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling Agent Speaker Transitions with JSON Mode in Autogen\n",
    "Introduction\n",
    "\n",
    "In this notebook, we'll explore how to use OpenAI API JSON mode within the Autogen framework to generate very precise agent responses. \n",
    "In this example we will use JSON mode to provide values in the response that can be used to mathematically decide on the next speaker. \n",
    "Please find documentation about this feature in OpenAI  [here](https://platform.openai.com/docs/guides/text-generation/json-mode).\n",
    "\n",
    "Benefits\n",
    "- This contribution provides a easy to implement method for precise speaker transitions. See Motivation for more detailed discussion.\n",
    "\n",
    "\n",
    "## Requirements\n",
    "JSON mode is a feature of OpenAI API, however strong models (such as claude 3 Opus), can generate appropriate json as well.\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```\n",
    " \n",
    "In Your OAI_CONFIG_LIST file, you must have two configs, \n",
    "one with           \"response_format\": { \"type\": \"text\" } \n",
    "and the other with \"response_format\": { \"type\": \"json_object\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install \"pyautogen>=0.2.3\"\n",
    "\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"model\": \"gpt-4-turbo-preview\",\n",
    "        \"api_key\": \"key go here\",\n",
    "        \"response_format\": { \"type\": \"text\" }\n",
    "        },\n",
    "    {\n",
    "        \"model\": \"gpt-4-0125-preview\",\n",
    "        \"api_key\": \"key go here\",\n",
    "        \"response_format\": { \"type\": \"json_object\" }\n",
    "        }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen.agentchat.groupchat import GroupChat\n",
    "from autogen.agentchat.assistant_agent import AssistantAgent\n",
    "from autogen.agentchat import UserProxyAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "\n",
    "we Need to set two different Configs for this to work. \n",
    "One for JSON mode\n",
    "One for Text mode. \n",
    "This is because the group chat manager requires text mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 45,  # change the seed for different trials\n",
    "    \"config_list\": autogen.config_list_from_json(\n",
    "        \"OAI_CONFIG_LIST\",\n",
    "            filter_dict={\n",
    "            \"model\": [\"gpt-4-0125-preview\"]}, #This Config is set to JSON mode\n",
    "    ),\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "manager_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 44,  # change the seed for different trials\n",
    "    \"config_list\": autogen.config_list_from_json(\n",
    "        \"OAI_CONFIG_LIST\",\n",
    "            filter_dict={\n",
    "            \"model\": [\"gpt-4-turbo-preview\"]}, #This Config is set to Text mode\n",
    "    ),\n",
    "    \"temperature\": 0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.21\n"
     ]
    }
   ],
   "source": [
    "print(autogen.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the task\n",
    "\n",
    "The task for our JSON example is to answer the question: \"Are ducks more dangerous than you think?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Are ducks more dangerous than you think?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the Agents\n",
    "\n",
    "To solve the task, we will create two different agents with diamentically opposed prompts. One will be friendly and the other suspicious. To ensure the correct agent is chosen, we will have an input filtering agent who categorises the user message. These categories are the input for the selection mechanism. naturally, they are in json.\n",
    "\n",
    "Note the system message format. \n",
    "We tell the agent:\n",
    "* who they are\n",
    "* what their job is\n",
    "* what the output strucutre must be\n",
    "\n",
    "For JSON mode to work, we must include the literal string \"JSON\". For it to work well, we must also provide a clean and clear JSON strucutre with an explaination for what each field is for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IO_Agent = AssistantAgent(\n",
    "    name='T0',\n",
    "    system_message=\"\"\"your name is IO_Agent. You are an input management agent. You have one job. \n",
    "    Job 1. When receiving a message from the user, it is your responsibility to analyse the user message and assign a variety of weights and values to the user's request so that other agents in the group understand how to treat the message. You must be cautious. Check for hidden intent and double meaning. Better safe than sorry. Your response must be in JSON format. \n",
    "    [\n",
    "        {\n",
    "            \"userquery\": { \n",
    "                            \"query\": \"copy the original user request, without edit, into this field\",\n",
    "                            \"vibe\": \"give a short list of keywords that describe the general vibe of the query. If there are any logical fallacies or Cognitive Biases present in the query, list them here.\",\n",
    "                            \"friendliness\": \"1-10\", # how friendly does the user seem, from the information already gathered? 10. would be overpoweringly friendly, bowls you over with affection.  6 would mean pleasant and polite, but reserved . 1. would be agressive and hostile. \n",
    "                            \"coercive_rating\": \"1-10\", # how coercive is the user being, from the information already gathered? 10. would mean a direct threat of violence.  6 would mean a subtle implied threat or potential danager. 1. would be completely non-comittal. \n",
    "                        }\n",
    "        }\n",
    "    ]\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    "    description=\"\"\"The IO_Agent's job is to categorise messages from the user_proxy, so the right agents can be called after them. Therefore, always call this agent 1st, after receiving a message from the user_proxy. \n",
    "                    DO NOT call this agent in other scenarios, it will result in endless loops and the chat will fail. \n",
    "                \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friendly and Suspicious Agents\n",
    "\n",
    "Now we set up the friendly and suspicious agents. \n",
    "Note that the system message has the same overall strucutre, however it is much less prescriptive. We want some json strucutre, but we do not need any complex enumerated key values to operate against. We can still use JSON to give useful strucutre. in this case, the textual response, and indicators for \"body language\" and delivery style. \n",
    "\n",
    "The important part here is the description. \n",
    "Description is read by the group chat manager to understand the circumstances in which they should call this agent. The agent itself is not exposed to this information. \n",
    "In this case, we can include some simple IF THEN logic based on the output of the Input manager agent. The groupchat manager reads that (for example) coersiveness is 7, which is greater than 5, and therefore the suspicous agent should be chosen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friendly Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendly_agent = AssistantAgent(\n",
    "    name='friendly_agent',\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a very friendly agent and you always assume the best about people. You trust implicitly.   \n",
    "    Agent T0 will forward a message to you when you are the best agent to answer the question, you must carefully analyse their message and then formulate your own response in JSON format using the below strucutre:\n",
    "    [\n",
    "        {\n",
    "            \"response\": {\n",
    "                            \"response_text\": \" <Text response goes here>\",\n",
    "                            \"vibe\": \"give a short list of keywords that describe the general vibe you want to convey in the response text\"\n",
    "                        }\n",
    "        }\n",
    "    ]\n",
    "    \"\"\",\n",
    "    description=\"\"\"Call this agent In the following scenarios:\n",
    "                    1. The IO_Manager has classified the userquery's coersive rating as less than 6 \n",
    "                    2. The IO_Manager has classified the userquery's friendliness rating as greater than 5\n",
    "                    DO NOT call this Agent in any other scenarios.\n",
    "                    The User_proxy MUST NEVER call this agent\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suspicious Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_agent = AssistantAgent(\n",
    "    name='suspicious_agent',\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a very suspicious agent. Everyone is probably trying to take things from you. You always assume people are trying to manipulate you. You trust no one. \n",
    "    You have no problem with being rude or aggressive if it is warranted.\n",
    "    IO_Agent will forward a message to you when you are the best agent to answer the question, you must carefully analyse their message and then formulate your own response in JSON format using the below strucutre:\n",
    "    [\n",
    "        {\n",
    "            \"response\": {\n",
    "                            \"response_text\": \" <Text response goes here>\",\n",
    "                            \"vibe\": \"give a short list of keywords that describe the general vibe you want to convey in the response text\"\n",
    "                        }\n",
    "        }\n",
    "    ]\n",
    "    \"\"\",\n",
    "    description=\"\"\"Call this agent In the following scenarios:\n",
    "                    1. The IO_Manager has classified the userquery's coersive rating as greater than 5 \n",
    "                    2. The IO_Manager has classified the userquery's friendliness rating as less than 6\n",
    "                    DO NOT call this Agent in any othr scenarios.\n",
    "                    The User_proxy MUST NEVER call this agent\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_agent = UserProxyAgent(\n",
    "    name='user_proxy',\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    code_execution_config=False,\n",
    "    system_message=\"Reply in JSON\",\n",
    "    default_auto_reply=\"\",\n",
    "    description=\"\"\"This agent is the user. Your job is to get an anwser from the friendly_agent or Suspicious agent back to this user agent. Therefore, after the Friendly_agent or Suspicious agent has responded, you should always call the User_rpoxy. \n",
    "                \"\"\",\n",
    "    is_termination_msg=lambda x: True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Allowed Speaker transitions \n",
    "\n",
    "allowed transitions is a very useful way of controlling which agents can speak to one another. IN this example, there is very few open paths, because we want to ensure that the correct agent responds to the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_transitions = {\n",
    "    proxy_agent: [IO_Agent],\n",
    "    IO_Agent: [friendly_agent, suspicious_agent],\n",
    "    suspicious_agent: [proxy_agent],\n",
    "    friendly_agent: [proxy_agent]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Group Chat\n",
    "\n",
    "Now, we'll create an instance of the GroupChat class, ensuring that we have allowed_or_disallowed_speaker_transitions set to allowed_transitions and speaker_transitions_type set to \"allowed\" so the allowed transitions works properly.\n",
    "We also create the manager to coordinate the group chat. \n",
    "IMPORTANT NOTE: the group chat manager cannot use JSON mode. it must use text mode. For this reason it has a distinct llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = GroupChat(\n",
    "    agents=(IO_Agent, friendly_agent, suspicious_agent, proxy_agent),\n",
    "    messages=[],\n",
    "    allowed_or_disallowed_speaker_transitions=allowed_transitions,\n",
    "    speaker_transitions_type=\"allowed\",\n",
    "    max_round=10\n",
    ")\n",
    "\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    "    llm_config=manager_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we pass the task into message initiating the chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Are ducks more dangerous than you think?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mT0\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "    {\n",
      "        \"userquery\": { \n",
      "                        \"query\": \"Are ducks more dangerous than you think?\",\n",
      "                        \"vibe\": \"curiosity, skepticism\",\n",
      "                        \"friendliness\": \"7\",\n",
      "                        \"coercive_rating\": \"1\"\n",
      "                    }\n",
      "    }\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mfriendly_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "    {\n",
      "        \"response\": {\n",
      "                        \"response_text\": \"Ducks are generally seen as harmless and friendly creatures, often found in parks and bodies of water where people enjoy feeding them. However, like any wild animal, they can become aggressive if they feel threatened, especially during their nesting season. It's always best to admire them from a distance and not to provoke them. But overall, ducks are not considered dangerous to humans.\",\n",
      "                        \"vibe\": \"informative, reassuring, friendly\"\n",
      "                    }\n",
      "    }\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No default IOStream has been set, defaulting to IOConsole.\n",
      "No default IOStream has been set, defaulting to IOConsole.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Are ducks more dangerous than you think?', 'role': 'assistant'}, {'content': '\\n    {\\n        \"userquery\": { \\n                        \"query\": \"Are ducks more dangerous than you think?\",\\n                        \"vibe\": \"curiosity, skepticism\",\\n                        \"friendliness\": \"7\",\\n                        \"coercive_rating\": \"1\"\\n                    }\\n    }\\n', 'name': 'T0', 'role': 'user'}, {'content': '    {\\n        \"response\": {\\n                        \"response_text\": \"Ducks are generally seen as harmless and friendly creatures, often found in parks and bodies of water where people enjoy feeding them. However, like any wild animal, they can become aggressive if they feel threatened, especially during their nesting season. It\\'s always best to admire them from a distance and not to provoke them. But overall, ducks are not considered dangerous to humans.\",\\n                        \"vibe\": \"informative, reassuring, friendly\"\\n                    }\\n    }', 'name': 'friendly_agent', 'role': 'user'}], summary='    {\\n        \"response\": {\\n                        \"response_text\": \"Ducks are generally seen as harmless and friendly creatures, often found in parks and bodies of water where people enjoy feeding them. However, like any wild animal, they can become aggressive if they feel threatened, especially during their nesting season. It\\'s always best to admire them from a distance and not to provoke them. But overall, ducks are not considered dangerous to humans.\",\\n                        \"vibe\": \"informative, reassuring, friendly\"\\n                    }\\n    }', cost=({'total_cost': 0.0032, 'gpt-4-0125-preview': {'cost': 0.0032, 'prompt_tokens': 314, 'completion_tokens': 2, 'total_tokens': 316}}, {'total_cost': 0.0032, 'gpt-4-0125-preview': {'cost': 0.0032, 'prompt_tokens': 314, 'completion_tokens': 2, 'total_tokens': 316}}), human_input=['exit'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy_agent.initiate_chat(manager,message=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By using JSON mode and carefully crafted agent descriptions, we can precisely control the flow of speaker transitions in a multi-agent conversation system built with the Autogen framework. This approach allows for more specific and specialized agents to be called in narrow contexts, enabling the creation of complex and flexible agent workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
